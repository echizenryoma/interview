## 统计学习概论

### 方法

* 监督学习（supervised learning）
* 非监督学习（unsupervised learning）
* 半监督学习（semi-supervised learning）
* 强化学习（reinforcement learning）

### 步骤

1. 得到一个有限的训练数据集合；
2. 确定包含所有可能的模型的假设空间，即学习模型的集合；
3. 确定模型选择的准则，即学习的策略，
4. 实现求解最优模型的算法，即学习的算法；
5. 通过学习方法选择最优模型；
6. 利用学习的最优模型对新数据进行预测或分析。

### 三要素

1. 模型（model）
2. 策略（strategy）
3. 算法（algorithm）

方法 = 模型 + 策略 + 算法

#### 模型

##### 决策函数模型

$$ \mathcal{F}=\{f|Y=f(X)\} $$  
参数空间：$$ \mathcal{F}=\{f|Y=f_\theta(X),\theta\in{\mathbf{R}^n}\} $$

##### 条件概率模型

$$ \mathcal{F}=\{P|P(Y|X)\} $$  
参数空间：$$ \mathcal{F}=\{f|P_\theta(Y|X),\theta\in{\mathbf{R}^n}\} $$

#### 策略

* 损失函数：一次预测的好坏
* 风险函数：平均意义下模型预测的好坏

##### 常用的损失函数

1. 0-1损失函数：$$ L(Y,f(x))=I(f(X)\neq Y)=\left\{\begin{array}{lc}1&Y\neq f(X)\\0&Y=f(X)\end{array}\right. $$
2. 平方损失函数：$$ L(Y,f(x))=(Y-f(X))^2 $$
3. 绝对损失函数：$$ L(Y,f(x))=|Y-f(X)| $$
4. 对数损失函数：$$ L(Y,f(x))=-\log {P(Y|X)} $$

#### 风险函数

$$ R_{exp}(f)=E_p[L(Y,f(X))]=\int_{X\times Y}L(y,f(x))P(x,y)\mathrm{d}x \mathrm{d}y $$

#### 经验风险/经验损失

$$ R_{emp}(f)=\frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i)) $$

#### 结构风险

$$ R_{srm}(f)=\frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i)) +\lambda J(f) $$，$$J(f) $$为模型的复杂度

### 算法

* 如果最优化问题有显式的解析式，算法比较简单
* 但通常解析式不存在，就需要数值计算的方法

### 方法

#### 生成方法

在生成方法中，模型表示了给定输入$$X$$产生输出$$Y$$的生成关系。典型的生成模型有：朴素贝叶斯法和隐马尔可夫模型。

##### 特点：

1. 生成方法可以还还原出联合概率分布$$P(X,Y)$$, 而判别方法则不能；
2. 生成方法的学习收敛速度更快， 即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；
3. 当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。

#### 判别方法

判别方法由数据直接学习决策函数$$f(X)$$或者条件概率分布$$P(Y|X)$$作为预测的模型， 即判别模型判别方法关心的是对给定的输入$$X$$, 应该预测什么样的输出$$Y$$. 典型的判别模型包括：K近邻法、感知机、决策树、逻辑斯谛回归模型、 最大熵模型、支持向量机、 提升方法和条件随机场等。

##### 特点：

1. 判别方法直接学习的是条件概率$$P(Y|X)$$或决策函数；
2. 生成方法的学习收敛速度更快， 即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；
3. 当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。


### 模型评估

* 训练误差：$$ R_{emp}(\hat f)=\frac{1}{N} \sum_{i=1}^N L(y_i,\hat f(x_i)) $$
* 测试误差：$$ e_{test}=\frac{1}{N'} \sum_{i=1}^{N'} L(y_i,\hat f(x_i)) $$

#### 过拟合

如果一味追求提高对训练数据的预测能力， 所选揆型的复杂度则往往会比真模型更高这种现象称为**过拟合**。

#### 模型复杂度

![](/assets/var_bias_sample.png)

### 交叉验证

* 简单交叉验证
* S折交叉验证
* 留一交叉验证

### 泛化能力
学习方法的泛化能力（generalization ability）是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。

#### 泛化误差

$$ R_{exp}(\hat f)=E_p[L(Y,\hat f(X))]=\int_{X\times Y}L(y,\hat f(x))P(x,y)\mathrm{d}x \mathrm{d}y $$

#### 泛化误差上界

$$ R(f)\le \hat R(f) + \varepsilon(d,N,\delta) $$，其中$$ \varepsilon(d,N,\delta)=\sqrt{\frac{1}{2N}(\log d+\log \frac{1}{\delta})} $$